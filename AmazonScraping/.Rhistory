library(rvest)
library(stringr)
library(tidyr)
library(NLP)
library(tm)
library(SnowballC)
url <- 'https://www.amazon.com/All-New-Amazon-Echo-Dot-Add-Alexa-To-Any-Room/product-reviews/B01DFKC2SO/ref=cm_cr_dp_see_all_btm?ie=UTF8&reviewerType=avp_only_reviews&showViewpoints=1&sortBy=recent'
webpage <- read_html(url)
selector_name = ".review-text"
fnames<-html_nodes(x = webpage, css = selector_name) %>%
html_text()
write(fnames,file= "S:\\varsha\\BDA\\text_analytics\\testfinal.txt")
wordpunct_tokenizer
wordpunct_tokenizer(fnames)
tt <- as.Token_Tokenizer(wordpunct_tokenizer)
tt
tt(fnames)
scan_tokenizer <- function(x)
scan(text = as.character(x), what = "character", quote = "",
quiet = TRUE)
tt <- Token_Tokenizer(scan_tokenizer)
tt(fnames)
st <- as.Span_Tokenizer(tt)
st(fnames)
library(tm)
library(SnowballC)
corpus.copy <- corpus <- Corpus(DataframeSource(data.frame(fnames)))
corpus.temp <- tm_map(corpus.copy, stemDocument, language = "english")
inspect(corpus)
inspect(corpus.copy)
inspect(corpus.temp)
corpus.final <- tm_map(corpus.temp, stemCompletion, dictionary = corpus.copy)
inspect(corpus.final)
score.sentiment <- function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
scores <- laply(sentences, function(sentence, pos.words, neg.words){
sentence <- gsub('[[:punct:]]', "", sentence)
sentence <- gsub('[[:cntrl:]]', "", sentence)
sentence <- gsub('\\d+', "", sentence)
sentence <- tolower(sentence)
word.list <- str_split(sentence, '\\s+')
words <- unlist(word.list)
pos.matches <- match(words, pos.words)
neg.matches <- match(words, neg.words)
pos.matches <- !is.na(pos.matches)
neg.matches <- !is.na(neg.matches)
score <- sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress)
scores.df <- data.frame(score=scores, text=sentences)
return(scores.df)
}
pos <- scan('S:\\varsha\\BDA\\text_analytics\\positive-words.txt',
what='character', comment.char=';') #folder with positive dictionary
neg <- scan('S:\\varsha\\BDA\\text_analytics\\negative-words.txt',
what='character', comment.char=';') #folder with negative dictionary
write(fnames,file= "S:\\varsha\\BDA\\text_analytics\\testfinal.txt")
pos <- scan('S:\\varsha\\BDA\\text_analytics\\positive-words.txt',
what='character', comment.char=';') #folder with positive dictionary
pos <- scan('Varsha Holennavar_sentiment analysis\\positive-words.txt',
what='character', comment.char=';') #folder with positive dictionary
pos <- scan('\\Users\\varshacholennavar\\Desktop\\Varsha Holennavar_sentiment analysis\\positive-words.txt',
what='character', comment.char=';') #folder with positive dictionary
pos <- scan('Users\\varshacholennavar\\Desktop\\Varsha Holennavar_sentiment analysis\\positive-words.txt',
what='character', comment.char=';') #folder with positive dictionary
pos <- scan('\\Users\\varshacholennavar\\Desktop\\Varsha Holennavar_sentiment analysis\\positive-words.txt',
what='character', comment.char=';') #folder with positive dictionary
pos <- scan('/Users/varshacholennavar/Desktop/Varsha Holennavar_sentiment analysis/positive-words.txt',
what='character', comment.char=';') #folder with positive dictionary
neg <- scan('/Users/varshacholennavar/Desktop/Varsha Holennavar_sentiment analysis/negative-words.txt',
what='character', comment.char=';') #folder with negative dictionary
pos.words <- c(pos, 'upgrade')
neg.words <- c(neg, 'wtf', 'wait', 'waiting', 'epicfail')
Dataset <- fnames
str(Dataset)
Dataset$text <- as.factor(Dataset)
str(Dataset$text)
scores <- score.sentiment(Dataset$text, pos.words, neg.words, .progress='text')
stat <- scores
stat <- mutate(stat, sentiment=ifelse(stat$score > 0, 'positive', ifelse(stat$score < 0, 'negative', 'neutral')))
score <- sum(pos.matches) - sum(neg.matches)
pos.matches <- match(words, pos.words)
neg.matches <- match(words, neg.words)
pos.matches <- !is.na(pos.matches)
neg.matches <- !is.na(neg.matches)
score <- sum(pos.matches) - sum(neg.matches)
return(score)
pos.matches <- match(words, pos.words)
neg.matches <- match(words, neg.words)
score.sentiment <- function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
scores <- laply(sentences, function(sentence, pos.words, neg.words){
sentence <- gsub('[[:punct:]]', "", sentence)
sentence <- gsub('[[:cntrl:]]', "", sentence)
sentence <- gsub('\\d+', "", sentence)
sentence <- tolower(sentence)
word.list <- str_split(sentence, '\\s+')
words <- unlist(word.list)
pos.matches <- match(words, pos.words)
neg.matches <- match(words, neg.words)
pos.matches <- !is.na(pos.matches)
neg.matches <- !is.na(neg.matches)
score <- sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress)
scores.df <- data.frame(score=scores, text=sentences)
return(scores.df)
}
pos <- scan('/Users/varshacholennavar/Desktop/Varsha Holennavar_sentiment analysis/positive-words.txt',
what='character', comment.char=';') #folder with positive dictionary
neg <- scan('/Users/varshacholennavar/Desktop/Varsha Holennavar_sentiment analysis/negative-words.txt',
what='character', comment.char=';') #folder with negative dictionary
pos.words <- c(pos, 'upgrade')
neg.words <- c(neg, 'wtf', 'wait', 'waiting', 'epicfail')
Dataset <- fnames
fnames<-html_nodes(x = webpage, css = selector_name) %>%
html_text()
Dataset <- fnames
str(Dataset)
Dataset$text <- as.factor(Dataset)
str(Dataset$text)
scores <- score.sentiment(Dataset$text, pos.words, neg.words, .progress='text')
stat <- scores
stat <- mutate(stat, sentiment=ifelse(stat$score > 0, 'positive', ifelse(stat$score < 0, 'negative', 'neutral')))
pos.matches <- match(words, pos.words)
write.csv(stat,file="/Users/varshacholennavar/Desktop/Varsha Holennavar_sentiment analysis/stats.csv")
XPATH_REVIEW_SECTION_2 = '//div[@data-hook="review"]'
XPATH_REVIEW_SECTION_3 = '//span[@data-hook="review-body"]//text()'
readreviewpage <- read_html(x=newpage)
reviews <- readreviewpage %>% html_nodes(xpath = XPATH_REVIEW_SECTION_2) %>%
html_nodes(xpath = XPATH_REVIEW_SECTION_3) %>% html_text()
if(length(reviews) > 0){
for (j in 1:length(reviews)){
r <- as.character(reviews[j])
filename <- paste("reviews/Review",p,".txt",sep = "")
write(r,file = filename)
p = p+1
}
}
XPATH_REVIEW_SECTION_2 = '//div[@data-hook="review"]'
XPATH_REVIEW_SECTION_3 = '//span[@data-hook="review-body"]//text()'
newpage<-'https://www.amazon.com/All-New-Amazon-Echo-Dot-Add-Alexa-To-Any-Room/product-reviews/B01DFKC2SO/ref=cm_cr_dp_see_all_btm?ie=UTF8&reviewerType=avp_only_reviews&showViewpoints=1&sortBy=recent'
readreviewpage <- read_html(x=newpage)
reviews <- readreviewpage %>% html_nodes(xpath = XPATH_REVIEW_SECTION_2) %>%
html_nodes(xpath = XPATH_REVIEW_SECTION_3) %>% html_text()
if(length(reviews) > 0){
for (j in 1:length(reviews)){
r <- as.character(reviews[j])
filename <- paste("reviews/Review",p,".txt",sep = "")
write(r,file = filename)
p = p+1
}
}
install.packages("DataCombine");
install.packages("MASS");
install.packages("lubridate")
#Reading the data
library("DataCombine");
library("MASS");
library("lubridate")
data = read.csv("/Users/varshacholennavar/Desktop/NYC Taxi and Limosine Commission/nyc_taxi_data_2014.csv",header = TRUE);
View(data)
unique(data$vendor_id)
install.packages("sqldf")
library(DataCombine)
library(MASS)
library(lubridate)
library(sqldf)
pickupHour = format(as.POSIXct(strptime(data$pickup_datetime,"%d/%m/%Y %H:%M",tz="")) ,format = "%H:%M")
pickupDate = format(as.POSIXct(strptime(data$pickup_datetime,"%d/%m/%Y %H:%M",tz="")) ,format = "%d/%d/%Y")
dropoffHour = format(as.POSIXct(strptime(data$pickup_datetime,"%d/%m/%Y %H:%M",tz="")),format = "%H:%M")
dropoffDate = format(as.POSIXct(strptime(data$pickup_datetime,"%d/%m/%Y %H:%M",tz="")),format = "%d/%d/%Y")
data$pickupDate <- pickupDate
data$pickupTime <- pickupHour
View(data)
testData = head(data,100)
View(testData)
pickupHour = format(as.POSIXct(strptime(testData$pickup_datetime,"%d-%m-%Y %H:%M:%S",tz="")) ,format = "%H:%M")
pickupHour
pickupHour = format(as.POSIXct(strptime(testData$pickup_datetime,"%Y-%m-%d %H:%M:%S",tz="")) ,format = "%H:%M")
pickupHour
pickupHour = format(as.POSIXct(strptime(testData$pickup_datetime,"%Y-%m-%d %H:%M:%S",tz="")) ,format = "%H:%M")
pickupDate = format(as.POSIXct(strptime(testData$pickup_datetime,"%Y-%m-%d %H:%M:%S",tz="")) ,format = "%d/%d/%Y")
dropoffHour = format(as.POSIXct(strptime(testData$pickup_datetime,"%Y-%m-%d %H:%M:%S",tz="")),format = "%H:%M")
dropoffDate = format(as.POSIXct(strptime(testData$pickup_datetime,"%Y-%m-%d %H:%M:%S",tz="")),format = "%d/%d/%Y")
testData$pickupDate <- pickupDate
testData$pickupTime <- pickupHour
View(testData)
pickupHour = format(as.POSIXct(strptime(testData$pickup_datetime,"%Y-%m-%d %H:%M:%S",tz="")) ,format = "%H:%M")
pickupDate = format(as.POSIXct(strptime(testData$pickup_datetime,"%Y-%m-%d %H:%M:%S",tz="")) ,format = "%Y-%m-%d")
dropoffHour = format(as.POSIXct(strptime(testData$pickup_datetime,"%Y-%m-%d %H:%M:%S",tz="")),format = "%H:%M")
dropoffDate = format(as.POSIXct(strptime(testData$pickup_datetime,"%Y-%m-%d %H:%M:%S",tz="")),format = "%Y-%m-%d")
testData$pickupDate <- pickupDate
testData$pickupTime <- pickupHour
View(testData)
testData$dropoffDate <- dropoffDate
testData$dropoffTime <- dropoffHour
install.packages
install.packages("geosphere")
clear
library(geosphere)
testData$Distance = distm (c(testData$pickup_longitude, testData$pickup_latitude),
c(testData$dropoff_longitude, testData$dropoff_latitude),
fun = distHaversine)
library(DataCombine)
library(MASS)
library(lubridate)
library(sqldf)
library(geosphere)
testData$Distance = distm (c(testData$pickup_longitude, testData$pickup_latitude),
c(testData$dropoff_longitude, testData$dropoff_latitude),
fun = distHaversine)
View(testData)
testData = testData[!(testData$pickup_longitude==0 | testData$pickup_latitude==0)]
testData = testData[!(testData$pickup_longitude==0 | testData$pickup_latitude==0),]
View(testData)
testData$Distance = distm (c(testData$pickup_longitude, testData$pickup_latitude),
c(testData$dropoff_longitude, testData$dropoff_latitude),
fun = distHaversine)
testData$Distance = distm (c(testData$pickup_latitude,testData$pickup_longitude),
c(testData$dropoff_latitude,testData$dropoff_longitude),
fun = distHaversine)
testData$Distance = distm (c(testData$dropoff_latitude,testData$dropoff_longitude),
c(testData$pickup_latitude,testData$pickup_longitude),
fun = distHaversine)
distm(c(-73.98779,40.76010),c(-73.95565,40.77963),fun = distHaversine)
Distance = distm (c(testData$dropoff_latitude,testData$dropoff_longitude),
c(testData$pickup_latitude,testData$pickup_longitude),
fun = distHaversine)
Distance = distm (c(testData$dropoff_latitude[1],testData$dropoff_longitude[1]),
c(testData$pickup_latitude[1],testData$pickup_longitude[1]),
fun = distHaversine)
Distanc
Distance
for(varb in 1:length(testData$vendor_id)){
Distance = distm (c(testData$dropoff_latitude[i],testData$dropoff_longitude[i]),
c(testData$pickup_latitude[i],testData$pickup_longitude[i]),
fun = distHaversine)
}
for(i in 1:length(testData$vendor_id)){
Distance = distm (c(testData$dropoff_latitude[i],testData$dropoff_longitude[i]),
c(testData$pickup_latitude[i],testData$pickup_longitude[i]),
fun = distHaversine)
}
i
Distance
for(i in 1:length(testData$vendor_id)){
Distance[i] = distm (c(testData$dropoff_latitude[i],testData$dropoff_longitude[i]),
c(testData$pickup_latitude[i],testData$pickup_longitude[i]),
fun = distHaversine)
}
cbind(testData,Distance)
testData = cbind(testData,Distance)
View(testData)
testData = head(data,100)
pickupHour = format(as.POSIXct(strptime(testData$pickup_datetime,"%Y-%m-%d %H:%M:%S",tz="")) ,format = "%H:%M")
pickupDate = format(as.POSIXct(strptime(testData$pickup_datetime,"%Y-%m-%d %H:%M:%S",tz="")) ,format = "%Y-%m-%d")
dropoffHour = format(as.POSIXct(strptime(testData$pickup_datetime,"%Y-%m-%d %H:%M:%S",tz="")),format = "%H:%M")
dropoffDate = format(as.POSIXct(strptime(testData$pickup_datetime,"%Y-%m-%d %H:%M:%S",tz="")),format = "%Y-%m-%d")
testData$pickupDate <- pickupDate
testData$pickupTime <- pickupHour
testData$dropoffDate <- dropoffDate
testData$dropoffTime <- dropoffHour
testData = testData[!(testData$pickup_longitude==0 | testData$pickup_latitude==0),]
for(i in 1:length(testData$vendor_id)){
Distance[i] = distm (c(testData$dropoff_latitude[i],testData$dropoff_longitude[i]),
c(testData$pickup_latitude[i],testData$pickup_longitude[i]),
fun = distHaversine)
Distance[i] = Distance[i]/1000
}
testData = cbind(testData,Distance)
View(testData)
testData$Distance[1]
testData$Distance[9]
testData$Distance[0]
booksData = file("BX-Books.csv", "r", blocking = FALSE)
setwd("/Users/varshacholennavar/Desktop/AmazonReviews/BX-CSV-Dump")
booksData = file("BX-Books.csv", "r", blocking = FALSE)
line=readLines(booksData)
line[0]
line[1]
line[2]
length(line)
for(i in 1:2){
print(line[i])
}
class(line)
for(i in 1:2){
f = strsplit(line[i],";")[[1]]
print(f)
}
for(i in 1:2){
f = strsplit(line[i],";")
print(f)
}
for(i in 1:2){
r = gsub("&amp;","&",line[i])
r = gsub(";","$$$",r)
r = gsub("\"$$$\"","\";\"",r)
r = gsub("\"","",r)
f = strsplit(r,";")
print(f)
}
r = gsub("&amp;","&",line[1])
e
r
r = gsub(";","$$$",r)
r
r = gsub("\"$$$\"","\";\"",r)
r
r = gsub(""$$$"","";"",r)
r = gsub("\"$$$\"","\";\"",r)
r
r = gsub("&amp;","&",line[1])
r
r = gsub(";","$$$",r)
r
r = gsub("&amp;","&",line[1])
r = gsub(";","$$$",r)
r = gsub("\"$$$\\\"","\";\"",r)
r
r = gsub("&amp;","&",line[1])
r = gsub(";","$$$",r)
r = gsub("\\","",r)
r = gsub("&amp;","&",line[1])
r = gsub(";","$$$",r)
r = gsub("\\","",r)
r
r = gsub("\\\"","",r)
r
r = gsub("\"$$$\"","\";\"",r)
r
r = gsub("&amp;","&",line[1])
r = gsub("\\\"","",r)
r = gsub(";","$$$",r)
r = gsub("\"$$$\"","\";\"",r)
r
r = gsub("&amp;","&",line[1])
r = gsub("\\\"","",r)
r
r = gsub(";","$$$",r)
r
r = gsub("&amp;","&",line[1])
r
r = gsub("\\","",r)
r = gsub("&amp;","&",line[1])
r = gsub("\\.|/|\\-|\"|\\s","",r)
r
r = gsub("&amp;","&",line[1])
r = gsub("\\.\\s","",r)
r
r = gsub("&amp;","&",line[1])
r = gsub("\\.|/|\\-|\|\\s","",r)
r = gsub("\\.|\\-|\|\\s","",r)
r = gsub("&amp;","&",line[1])
r = gsub("[\t\n]","",r)
r
r = gsub("&amp;","&",line[1])
r = gsub("[\]","",r)
r = gsub("[\\]","",r)
r
r = gsub("([\])","",r)
r = gsub("(\)","",r)
r = gsub("(\\)","",r)
r
r = gsub('\"',"",r)
r
r = gsub("&amp;","&",line[2])
r = gsub('\"',"",r)
r
r = gsub("&amp;","&",line[2])
r
r = gsub('\"',"",r,fixed = TRUE)
r
r = gsub("&amp;","&",line[2])
r = gsub("([\\])",r,fixed = TRUE)
r = gsub("([\\])",r)
r = gsub("([\\])","",r)
r
r = gsub(";","$$$",r)
r
r = gsub("\"$$$\"","\";\"",r)
r
r = gsub("\"$$$\\\"","\";\"",r)
r
pwd
getwd()
list.files()
r
for(i in 2:length(line)){
p = gsub("&amp;","&",line[i])
q = gsub(";","$$$",p)
r = gsub("\"$$$\"","\";\"",q)
s = gsub("\"","",r)
}
write(s, file = "testData.txt")
dataFile = ''
for(i in 2:length(line)){
p = gsub("&amp;","&",line[i])
q = gsub(";","$$$",p)
r = gsub("\"$$$\"","\";\"",q)
s = gsub("\"","",r)
if(i == 2)
dataFile = dataFile + s;
else
dataFile = dataFile + s + "\n"
}
write(s, file = "testData.txt")
for(i in 2:length(line)){
p = gsub("&amp;","&",line[i])
q = gsub(";","$$$",p)
r = gsub("\"$$$\"","\";\"",q)
s = gsub("\"","",r)
write(s,file="testData.txt",append=TRUE)
}
p = gsub("&amp;","&",line[2])
p = gsub("'","",p)
p = gsub("\\\"","",p)
p = gsub("\";", "\"æ",p)
p
p = gsub("&amp;","&",line[2])
p = gsub("\";", "\"æ",p)
p
p = gsub("&amp;","&",line[2])
p = gsub("'","")
p = gsub("\";", "\"æ",p)
p = gsub("&amp;","&",line[2])
p = gsub("'","",p)
p = gsub("\";", "\"æ",p)
p
for(i in 2:length(line)){
p = gsub("&amp;","&",line[2])
p = gsub("'","",p)
p = gsub("\";", "\"æ",p)
write(s,file="testData.txt",append=TRUE)
}
for(i in 2:length(line)){
p = gsub("&amp;","&",line[2])
p = gsub("'","",p)
p = gsub("\";", "\"æ",p)
write(s,file="testData.txt",append=TRUE)
}
for(i in 2:length(line)){
p = gsub("&amp;","&",line[i])
p = gsub("'","",p)
p = gsub("\";", "\"æ",p)
write(s,file="testData.txt",append=TRUE)
}
booksData = file("BX-Books.csv", "r", blocking = FALSE)
line = readLines(booksData)
length(line)
line[5]
line[500]
line[5000]
line[50000]
line[500000]
for(i in 2:length(line)){
p = gsub("&amp;","&",line[i])
p = gsub("'","",p)
p = gsub("\";", "\"æ",p)
write(s,file="testData.txt",append=TRUE)
}
booksData = file("BX-Books.csv", "r", blocking = FALSE)
line = readLines(booksData)
for(i in 2:5){
p = gsub("&amp;","&",line[i])
p = gsub("'","",p)
p = gsub("\";", "\"æ",p)
write(s,file="testData.txt",append=TRUE)
}
for(i in 2:5){
p = gsub("&amp;","&",line[i])
p = gsub("'","",p)
p = gsub("\";", "\"æ",p)
write(p,file="testData.txt",append=TRUE)
}
for(i in 2:length(line)){
p = gsub("&amp;","&",line[i])
p = gsub("'","",p)
p = gsub("\";", "\"æ",p)
write(p,file="testData.txt",append=TRUE)
}
for(i in 2:length(line)){
p = gsub("&amp;","&",line[i])
p = gsub("'","",p)
p = gsub("\\\"","",p)
p = gsub("\";", "\"æ",p)
write(p,file="testData.txt",append=TRUE)
}
