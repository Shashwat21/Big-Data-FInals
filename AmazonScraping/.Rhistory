c(testData$dropoff_longitude, testData$dropoff_latitude),
fun = distHaversine)
View(testData)
testData = testData[!(testData$pickup_longitude==0 | testData$pickup_latitude==0)]
testData = testData[!(testData$pickup_longitude==0 | testData$pickup_latitude==0),]
View(testData)
testData$Distance = distm (c(testData$pickup_longitude, testData$pickup_latitude),
c(testData$dropoff_longitude, testData$dropoff_latitude),
fun = distHaversine)
testData$Distance = distm (c(testData$pickup_latitude,testData$pickup_longitude),
c(testData$dropoff_latitude,testData$dropoff_longitude),
fun = distHaversine)
testData$Distance = distm (c(testData$dropoff_latitude,testData$dropoff_longitude),
c(testData$pickup_latitude,testData$pickup_longitude),
fun = distHaversine)
distm(c(-73.98779,40.76010),c(-73.95565,40.77963),fun = distHaversine)
Distance = distm (c(testData$dropoff_latitude,testData$dropoff_longitude),
c(testData$pickup_latitude,testData$pickup_longitude),
fun = distHaversine)
Distance = distm (c(testData$dropoff_latitude[1],testData$dropoff_longitude[1]),
c(testData$pickup_latitude[1],testData$pickup_longitude[1]),
fun = distHaversine)
Distanc
Distance
for(varb in 1:length(testData$vendor_id)){
Distance = distm (c(testData$dropoff_latitude[i],testData$dropoff_longitude[i]),
c(testData$pickup_latitude[i],testData$pickup_longitude[i]),
fun = distHaversine)
}
for(i in 1:length(testData$vendor_id)){
Distance = distm (c(testData$dropoff_latitude[i],testData$dropoff_longitude[i]),
c(testData$pickup_latitude[i],testData$pickup_longitude[i]),
fun = distHaversine)
}
i
Distance
for(i in 1:length(testData$vendor_id)){
Distance[i] = distm (c(testData$dropoff_latitude[i],testData$dropoff_longitude[i]),
c(testData$pickup_latitude[i],testData$pickup_longitude[i]),
fun = distHaversine)
}
cbind(testData,Distance)
testData = cbind(testData,Distance)
View(testData)
testData = head(data,100)
pickupHour = format(as.POSIXct(strptime(testData$pickup_datetime,"%Y-%m-%d %H:%M:%S",tz="")) ,format = "%H:%M")
pickupDate = format(as.POSIXct(strptime(testData$pickup_datetime,"%Y-%m-%d %H:%M:%S",tz="")) ,format = "%Y-%m-%d")
dropoffHour = format(as.POSIXct(strptime(testData$pickup_datetime,"%Y-%m-%d %H:%M:%S",tz="")),format = "%H:%M")
dropoffDate = format(as.POSIXct(strptime(testData$pickup_datetime,"%Y-%m-%d %H:%M:%S",tz="")),format = "%Y-%m-%d")
testData$pickupDate <- pickupDate
testData$pickupTime <- pickupHour
testData$dropoffDate <- dropoffDate
testData$dropoffTime <- dropoffHour
testData = testData[!(testData$pickup_longitude==0 | testData$pickup_latitude==0),]
for(i in 1:length(testData$vendor_id)){
Distance[i] = distm (c(testData$dropoff_latitude[i],testData$dropoff_longitude[i]),
c(testData$pickup_latitude[i],testData$pickup_longitude[i]),
fun = distHaversine)
Distance[i] = Distance[i]/1000
}
testData = cbind(testData,Distance)
View(testData)
testData$Distance[1]
testData$Distance[9]
testData$Distance[0]
booksData = file("BX-Books.csv", "r", blocking = FALSE)
setwd("/Users/varshacholennavar/Desktop/AmazonReviews/BX-CSV-Dump")
booksData = file("BX-Books.csv", "r", blocking = FALSE)
line=readLines(booksData)
line[0]
line[1]
line[2]
length(line)
for(i in 1:2){
print(line[i])
}
class(line)
for(i in 1:2){
f = strsplit(line[i],";")[[1]]
print(f)
}
for(i in 1:2){
f = strsplit(line[i],";")
print(f)
}
for(i in 1:2){
r = gsub("&amp;","&",line[i])
r = gsub(";","$$$",r)
r = gsub("\"$$$\"","\";\"",r)
r = gsub("\"","",r)
f = strsplit(r,";")
print(f)
}
r = gsub("&amp;","&",line[1])
e
r
r = gsub(";","$$$",r)
r
r = gsub("\"$$$\"","\";\"",r)
r
r = gsub(""$$$"","";"",r)
r = gsub("\"$$$\"","\";\"",r)
r
r = gsub("&amp;","&",line[1])
r
r = gsub(";","$$$",r)
r
r = gsub("&amp;","&",line[1])
r = gsub(";","$$$",r)
r = gsub("\"$$$\\\"","\";\"",r)
r
r = gsub("&amp;","&",line[1])
r = gsub(";","$$$",r)
r = gsub("\\","",r)
r = gsub("&amp;","&",line[1])
r = gsub(";","$$$",r)
r = gsub("\\","",r)
r
r = gsub("\\\"","",r)
r
r = gsub("\"$$$\"","\";\"",r)
r
r = gsub("&amp;","&",line[1])
r = gsub("\\\"","",r)
r = gsub(";","$$$",r)
r = gsub("\"$$$\"","\";\"",r)
r
r = gsub("&amp;","&",line[1])
r = gsub("\\\"","",r)
r
r = gsub(";","$$$",r)
r
r = gsub("&amp;","&",line[1])
r
r = gsub("\\","",r)
r = gsub("&amp;","&",line[1])
r = gsub("\\.|/|\\-|\"|\\s","",r)
r
r = gsub("&amp;","&",line[1])
r = gsub("\\.\\s","",r)
r
r = gsub("&amp;","&",line[1])
r = gsub("\\.|/|\\-|\|\\s","",r)
r = gsub("\\.|\\-|\|\\s","",r)
r = gsub("&amp;","&",line[1])
r = gsub("[\t\n]","",r)
r
r = gsub("&amp;","&",line[1])
r = gsub("[\]","",r)
r = gsub("[\\]","",r)
r
r = gsub("([\])","",r)
r = gsub("(\)","",r)
r = gsub("(\\)","",r)
r
r = gsub('\"',"",r)
r
r = gsub("&amp;","&",line[2])
r = gsub('\"',"",r)
r
r = gsub("&amp;","&",line[2])
r
r = gsub('\"',"",r,fixed = TRUE)
r
r = gsub("&amp;","&",line[2])
r = gsub("([\\])",r,fixed = TRUE)
r = gsub("([\\])",r)
r = gsub("([\\])","",r)
r
r = gsub(";","$$$",r)
r
r = gsub("\"$$$\"","\";\"",r)
r
r = gsub("\"$$$\\\"","\";\"",r)
r
pwd
getwd()
list.files()
r
for(i in 2:length(line)){
p = gsub("&amp;","&",line[i])
q = gsub(";","$$$",p)
r = gsub("\"$$$\"","\";\"",q)
s = gsub("\"","",r)
}
write(s, file = "testData.txt")
dataFile = ''
for(i in 2:length(line)){
p = gsub("&amp;","&",line[i])
q = gsub(";","$$$",p)
r = gsub("\"$$$\"","\";\"",q)
s = gsub("\"","",r)
if(i == 2)
dataFile = dataFile + s;
else
dataFile = dataFile + s + "\n"
}
write(s, file = "testData.txt")
for(i in 2:length(line)){
p = gsub("&amp;","&",line[i])
q = gsub(";","$$$",p)
r = gsub("\"$$$\"","\";\"",q)
s = gsub("\"","",r)
write(s,file="testData.txt",append=TRUE)
}
p = gsub("&amp;","&",line[2])
p = gsub("'","",p)
p = gsub("\\\"","",p)
p = gsub("\";", "\"æ",p)
p
p = gsub("&amp;","&",line[2])
p = gsub("\";", "\"æ",p)
p
p = gsub("&amp;","&",line[2])
p = gsub("'","")
p = gsub("\";", "\"æ",p)
p = gsub("&amp;","&",line[2])
p = gsub("'","",p)
p = gsub("\";", "\"æ",p)
p
for(i in 2:length(line)){
p = gsub("&amp;","&",line[2])
p = gsub("'","",p)
p = gsub("\";", "\"æ",p)
write(s,file="testData.txt",append=TRUE)
}
for(i in 2:length(line)){
p = gsub("&amp;","&",line[2])
p = gsub("'","",p)
p = gsub("\";", "\"æ",p)
write(s,file="testData.txt",append=TRUE)
}
for(i in 2:length(line)){
p = gsub("&amp;","&",line[i])
p = gsub("'","",p)
p = gsub("\";", "\"æ",p)
write(s,file="testData.txt",append=TRUE)
}
booksData = file("BX-Books.csv", "r", blocking = FALSE)
line = readLines(booksData)
length(line)
line[5]
line[500]
line[5000]
line[50000]
line[500000]
for(i in 2:length(line)){
p = gsub("&amp;","&",line[i])
p = gsub("'","",p)
p = gsub("\";", "\"æ",p)
write(s,file="testData.txt",append=TRUE)
}
booksData = file("BX-Books.csv", "r", blocking = FALSE)
line = readLines(booksData)
for(i in 2:5){
p = gsub("&amp;","&",line[i])
p = gsub("'","",p)
p = gsub("\";", "\"æ",p)
write(s,file="testData.txt",append=TRUE)
}
for(i in 2:5){
p = gsub("&amp;","&",line[i])
p = gsub("'","",p)
p = gsub("\";", "\"æ",p)
write(p,file="testData.txt",append=TRUE)
}
for(i in 2:length(line)){
p = gsub("&amp;","&",line[i])
p = gsub("'","",p)
p = gsub("\";", "\"æ",p)
write(p,file="testData.txt",append=TRUE)
}
for(i in 2:length(line)){
p = gsub("&amp;","&",line[i])
p = gsub("'","",p)
p = gsub("\\\"","",p)
p = gsub("\";", "\"æ",p)
write(p,file="testData.txt",append=TRUE)
}
library("dplyr")
library("XML")
library("stringr")
library("rvest")
library("audio")
#Remove all white space
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
#Function to scrape Amazon Reviews
scrapeReviews <- function(doc){
revAuthor = html_nodes(doc, ".author") %>% html_text()
revText   = html_nodes(doc,".review-text") %>% html_text()
revRating = doc %>% html_nodes("#cm_cr-review_list  .review-rating") %>% html_text() %>% str_extract("\\d") %>% as.numeric()
df = data.frame(revAuthor,revText,revRating,stringsAsFactors = F)
return(df)
}
#Product Code
productCode = "B00WK47VEW"
prodURL = paste0("https://www.amazon.com/dp/",productCode)
readURL = read_html(prodURL)
#Fetching Product Name from Amazon
productName = readURL %>% html_nodes("#productTitle")%>% html_text() %>% gsub("\n", "", .)%>% trim()
#Scraping Customer Name, Review and Ratings
allReviews = NULL
for(pageNum in 1:330){
url = paste0("https://www.amazon.com/product-review/", productCode,"/?pageNumber=",pageNum)
doc =read_html(url)
amazonRev = scrapeReviews(doc)
allReviews = rbind(allReviews,cbind(productName,amazonRev))
}
write.csv(allReviews, file = "ProductReviews-New.csv",row.names=FALSE)
View(allReviews)
pageNum
url = paste0("https://www.amazon.com/product-review/", productCode,"/?pageNumber=",11)
doc =read_html(url)
amazonRev = scrapeReviews(doc)
amazonRev = scrapeReviews(doc)
scrapeReviews <- function(doc){
revAuthor = html_nodes(doc, ".author") %>% html_text()
revText   = html_nodes(doc,".review-text") %>% html_text()
#revRating = doc %>% html_nodes("#cm_cr-review_list  .review-rating") %>% html_text() %>% str_extract("\\d") %>% as.numeric()
df = data.frame(revAuthor,revText,stringsAsFactors = F)
return(df)
}
amazonRev = scrapeReviews(doc)
doc
for(pageNum in 1:1){
url = paste0("https://www.amazon.com/product-review/", productCode,"/?pageNumber=",pageNum)
document =read_html(url)
amazonRev = scrapeReviews(document)
allReviews = rbind(allReviews,cbind(productName,amazonRev))
}
url = paste0("https://www.amazon.com/product-review/", productCode,"/?pageNumber=",1)
document =read_html(url)
amazonRev = scrapeReviews(document)
allReviews = rbind(allReviews,cbind(productName,amazonRev))
allReviews = NULL
allReviews = rbind(allReviews,cbind(productName,amazonRev))
allReviews = NULL
url = paste0("https://www.amazon.com/product-review/", productCode,"/?pageNumber=",11)
document =read_html(url)
amazonRev = scrapeReviews(document)
url = paste0("https://www.amazon.com/product-review/", productCode,"/?pageNumber=",11)
document =read_html(url)
revAuthor = html_nodes(document, ".author") %>% html_text()
revText   = html_nodes(document,".review-text") %>% html_text()
df = data.frame(revAuthor,revText,stringsAsFactors = F)
revAuthor
revRating
revText
url = paste0("https://www.amazon.com/product-review/", productCode,"/?pageNumber=",11)
document = html(url)
revAuthor = document %>% html_nodes(xpath="//*[contains(concat( " ", @class, " " ), concat( " ", "author", " " ))]") %>% html_text()
revAuthor = html_nodes(document, ".review-byline .author") %>% html_text()
revAuthor
revText   = html_nodes(document,".review-text") %>% html_text()
revRating = doc %>% html_nodes("#cm_cr-review_list  .review-rating") %>% html_text() %>% str_extract("\\d") %>% as.numeric()
df = data.frame(revAuthor,revText,stringsAsFactors = F)
#Remove all white space
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
#Function to scrape Amazon Reviews
scrapeReviews <- function(doc){
revAuthor = html_nodes(doc, ".review-byline .author") %>% html_text()
revText   = html_nodes(doc,"#cm_cr-review_list .review-text") %>% html_text()
revRating = doc %>% html_nodes("#cm_cr-review_list  .review-rating") %>% html_text() %>% str_extract("\\d") %>% as.numeric()
df = data.frame(revAuthor,revText,stringsAsFactors = F)
return(df)
}
#Product Code
productCode = "B00WK47VEW"
prodURL = paste0("https://www.amazon.com/dp/",productCode)
readURL = read_html(prodURL)
#Fetching Product Name from Amazon
productName = readURL %>% html_nodes("#productTitle")%>% html_text() %>% gsub("\n", "", .)%>% trim()
#Scraping Customer Name, Review and Ratings
allReviews = NULL
for(pageNum in 1:300){
url = paste0("https://www.amazon.com/product-review/", productCode,"/?pageNumber=",pageNum)
document =read_html(url)
amazonRev = scrapeReviews(document)
allReviews = rbind(allReviews,cbind(productName,amazonRev))
}
write.csv(allReviews, file = "ProductReviews-New.csv",row.names=FALSE)
View(allReviews)
productCode = "B01LWWY3E2" #Beats-Solo-3
prodURL = paste0("https://www.amazon.com/dp/",productCode)
readURL = read_html(prodURL)
#Fetching Product Name from Amazon
productName = readURL %>% html_nodes("#productTitle")%>% html_text() %>% gsub("\n", "", .)%>% trim()
#Scraping Customer Name, Review and Ratings
allReviews = NULL
for(pageNum in 1:150){
url = paste0("https://www.amazon.com/product-review/", productCode,"/?pageNumber=",pageNum)
document =read_html(url)
amazonRev = scrapeReviews(document)
allReviews = rbind(allReviews,cbind(productName,amazonRev))
}
write.csv(allReviews, file = "ProductReviews-New.csv",row.names=FALSE,append = TRUE)
productCode = "B00WK47VEW" #Bose-SoundLinkMini
#productCode = "B01LWWY3E2" #Beats-Solo-3
prodURL = paste0("https://www.amazon.com/dp/",productCode)
readURL = read_html(prodURL)
#Fetching Product Name from Amazon
productName = readURL %>% html_nodes("#productTitle")%>% html_text() %>% gsub("\n", "", .)%>% trim()
#Scraping Customer Name, Review and Ratings
allReviews = NULL
for(pageNum in 1:10){
url = paste0("https://www.amazon.com/product-review/", productCode,"/?pageNumber=",pageNum)
document =read_html(url)
amazonRev = scrapeReviews(document)
allReviews = rbind(allReviews,cbind(productName,amazonRev))
}
#writ
write.table(allReviews,"ProductReviews-New.csv", row.names=F,na="NA",append=T, quote= FALSE, sep=",", col.names=F)
allReviews = NULL
for(pageNum in 11:300){
url = paste0("https://www.amazon.com/product-review/", productCode,"/?pageNumber=",pageNum)
document =read_html(url)
amazonRev = scrapeReviews(document)
allReviews = rbind(allReviews,cbind(productName,amazonRev))
}
#write.csv(allReviews, file = "ProductReviews-New.csv",row.names=FALSE,append = TRUE)
write.table(allReviews,"ProductReviews-New.csv", row.names=F,na="NA",append=T, quote= FALSE, sep=",", col.names=F)
productCode = "B01E3SNO1G" #Bose Quiet Comfort QC-35
prodURL = paste0("https://www.amazon.com/dp/",productCode)
readURL = read_html(prodURL)
#Fetching Product Name from Amazon
productName = readURL %>% html_nodes("#productTitle")%>% html_text() %>% gsub("\n", "", .)%>% trim()
#Scraping Customer Name, Review and Ratings
allReviews = NULL
for(pageNum in 1:270){
url = paste0("https://www.amazon.com/product-review/", productCode,"/?pageNumber=",pageNum)
document =read_html(url)
amazonRev = scrapeReviews(document)
allReviews = rbind(allReviews,cbind(productName,amazonRev))
}
#write.csv(allReviews, file = "ProductReviews-New.csv",row.names=FALSE,append = TRUE)
write.table(allReviews,"ProductReviews-New.csv", row.names=F,na="NA",append=T, quote= FALSE, sep=",", col.names=F)
productCode = "B00ZV9PXP2" #AmazonKindle
prodURL = paste0("https://www.amazon.com/dp/",productCode)
readURL = read_html(prodURL)
#Fetching Product Name from Amazon
productName = readURL %>% html_nodes("#productTitle")%>% html_text() %>% gsub("\n", "", .)%>% trim()
#Scraping Customer Name, Review and Ratings
allReviews = NULL
for(pageNum in 1:600){
url = paste0("https://www.amazon.com/product-review/", productCode,"/?pageNumber=",pageNum)
document =read_html(url)
amazonRev = scrapeReviews(document)
allReviews = rbind(allReviews,cbind(productName,amazonRev))
}
#write.csv(allReviews, file = "ProductReviews-New.csv",row.names=FALSE,append = TRUE)
write.table(allReviews,"ProductReviews-New.csv", row.names=F,na="NA",append=T, quote= FALSE, sep=",", col.names=F)
install.packages("sparklyr")
#connect to spark
library(sparklyr)
library(dplyr)
sc <- spark_connect(config = "Apache Spark-ic")
install.packages("aws.s3", repos = c("cloudyr" = "http://cloudyr.github.io/drat"))
library("aws.s3")
Sys.setenv("AWS_ACCESS_KEY_ID" = "AKIAJM2RRWHOTKTD3KDA","AWS_SECRET_ACCESS_KEY" = "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")
usercsvobj = get_object("s3://bookreviews21/BX-BookRatings.csv")
csvcharobj <- rawToChar(usercsvobj)
con <- textConnection(csvcharobj)
data <- read.csv(con)
head(data)
usercsvobj = get_object("s3://bookreviews21/BX-Book-Ratings.csv")
csvcharobj <- rawToChar(usercsvobj)
con <- textConnection(csvcharobj)
data <- read.csv(con)
head(data)
getwd()
list.files()
df = read.csv(file = "ProductReviews.csv",header = TRUE)
View(df)
put_object(file = "ProductReveiws.csv",object = df,bucket = "s3://bookreviews21/SentimentAnalysis/")
put_object(file = "ProductReveiws.csv",object = "ProductReviews.csv",bucket = "s3://bookreviews21/SentimentAnalysis/")
tmp = tempfile()
put_object(tmp,object = "ProductReviews.csv",bucket = "s3://bookreviews21/SentimentAnalysis/")
zz <- rawConnection(raw(0), "r+")
put_object(file = rawConnectionValue(zz),object = "ProductReviews.csv",bucket = "s3://bookreviews21/SentimentAnalysis/")
put_object(file = "ProductReviews.csv",bucket = "s3://bookreviews21/SentimentAnalysis/")
getwd()
system("/usr/local/bin/hadoop-2.8.0/bin/hadoop fs -put /Users/varshacholennavar/Desktop/AmazonReviews/AmazonScraping/ProductReviews.csv /SentimentAnalysis/")
library("dplyr")
library("XML")
library("stringr")
library("rvest")
library("audio")
library("aws.s3")
#Remove all white space
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
#Function to scrape Amazon Reviews
scrapeReviews <- function(doc){
revAuthor = html_nodes(doc, ".review-byline .author") %>% html_text()
revText   = html_nodes(doc,"#cm_cr-review_list .review-text") %>% html_text()
revRating = doc %>% html_nodes("#cm_cr-review_list  .review-rating") %>% html_text() %>% str_extract("\\d") %>% as.numeric()
df = data.frame(revAuthor,revText,revRating,stringsAsFactors = F)
return(df)
}
productCode = "B00ZV9PXP2" #AmazonKindle
prodURL = paste0("https://www.amazon.com/dp/",productCode)
readURL = read_html(prodURL)
#Fetching Product Name from Amazon
productName = readURL %>% html_nodes("#productTitle")%>% html_text() %>% gsub("\n", "", .)%>% trim()
#Scraping Customer Name, Review and Ratings
allReviews = NULL
for(pageNum in 1:60){
url = paste0("https://www.amazon.com/product-review/", productCode,"/?pageNumber=",pageNum)
document =read_html(url)
amazonRev = scrapeReviews(document)
allReviews = rbind(allReviews,cbind(productName,amazonRev))
}
write.csv(allReviews, file = "ProductReviews.csv",row.names=FALSE)
